# PB-GSE Google Colab Guide

H∆∞·ªõng d·∫´n ch·∫°y PB-GSE tr√™n Google Colab m·ªôt c√°ch ƒë·∫ßy ƒë·ªß.

## üöÄ Quick Start

### 1. Setup trong Colab

```python
# Clone repository
!git clone https://github.com/your-repo/PB-GSE.git
%cd PB-GSE

# Setup environment
!python setup_colab.py

# Test installation
!python pb_gse/scripts/colab_demo.py
```

### 2. Ch·∫°y Demo nhanh

```python
# Ch·∫°y demo v·ªõi synthetic data
!python pb_gse/scripts/colab_demo.py
```

### 3. Ch·∫°y th√≠ nghi·ªám ƒë·∫ßy ƒë·ªß

```python
# Ch·∫°y experiment pipeline ho√†n ch·ªânh
!python pb_gse/scripts/run_experiment.py --config pb_gse/configs/experiment.yaml --save_dir ./colab_outputs
```

## üìã Chi ti·∫øt t·ª´ng b∆∞·ªõc

### B∆∞·ªõc 1: C√†i ƒë·∫∑t v√† Setup

```python
import os
import sys

# Clone repo n·∫øu ch∆∞a c√≥
if not os.path.exists('PB-GSE'):
    !git clone https://github.com/your-repo/PB-GSE.git

%cd PB-GSE

# Install requirements
!pip install torch torchvision numpy matplotlib scikit-learn PyYAML tqdm

# Setup directories
!mkdir -p data outputs outputs/logs outputs/models outputs/probs

# Add to Python path
sys.path.append('/content/PB-GSE')
```

### B∆∞·ªõc 2: Test Import v√† Dataset

```python
# Test imports
from pb_gse.data.datasets import CIFAR10LT
from pb_gse.models.backbones import ResNet32
from pb_gse.models.gating import PACBayesGating
from pb_gse.models.plugin_rule import PluginOptimizer
from pb_gse.models.metrics import SelectiveMetrics

print("‚úì All imports successful!")

# Test dataset
import torch
from pb_gse.data.transforms import get_transforms

config = {
    'data': {
        'name': 'cifar10_lt',
        'augmentation': {
            'train': {'rand_augment': {'n': 2, 'm': 10}},
            'test': {'center_crop': True}
        }
    }
}

transform_train, transform_test = get_transforms(config)
lt_dataset = CIFAR10LT(root='./data', imbalance_factor=100, seed=42)
train_dataset, test_dataset, group_info = lt_dataset.get_datasets(transform_train, transform_test)

print(f"‚úì Dataset: {len(train_dataset)} train, {len(test_dataset)} test")
print(f"‚úì Groups: {group_info}")
```

### B∆∞·ªõc 3: Ch·∫°y Pipeline ƒë∆°n gi·∫£n

```python
# Ch·∫°y demo pipeline
!python pb_gse/scripts/colab_demo.py
```

### B∆∞·ªõc 4: Training Base Models (tu·ª≥ ch·ªçn)

```python
# Train t·ª´ng model ri√™ng l·∫ª v·ªõi epochs ng·∫Øn cho demo
configs = ['base_crt.yaml', 'base_ldam.yaml', 'base_cbfocal.yaml']

for config_file in configs:
    print(f"Training with {config_file}...")
    !python pb_gse/scripts/train_base.py \
        --config pb_gse/configs/experiment.yaml \
        --model_config pb_gse/configs/{config_file} \
        --save_dir ./colab_outputs \
        --device cuda
```

### B∆∞·ªõc 5: Full Pipeline

```python
# Ch·∫°y to√†n b·ªô pipeline
!python pb_gse/scripts/run_experiment.py \
    --config pb_gse/configs/experiment.yaml \
    --save_dir ./colab_outputs \
    --device cuda
```

## ‚öôÔ∏è C·∫•u h√¨nh cho Colab

### ƒêi·ªÅu ch·ªânh config cho Colab

```python
import yaml

# Load v√† modify config cho Colab
with open('pb_gse/configs/experiment.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Gi·∫£m epochs cho demo nhanh
config['data']['batch_size'] = 128  # Gi·∫£m batch size
config['data']['num_workers'] = 2   # Gi·∫£m workers
config['data']['pin_memory'] = False # T·∫Øt pin_memory

# S·ª≠a base model epochs
base_configs = ['pb_gse/configs/base_crt.yaml',
                'pb_gse/configs/base_ldam.yaml',
                'pb_gse/configs/base_cbfocal.yaml']

for config_path in base_configs:
    with open(config_path, 'r') as f:
        base_config = yaml.safe_load(f)

    # Gi·∫£m epochs cho demo
    if 'stage1' in base_config['base_model']:
        base_config['base_model']['stage1']['epochs'] = 10
    if 'stage2' in base_config['base_model']:
        base_config['base_model']['stage2']['epochs'] = 5
    else:
        base_config['base_model']['epochs'] = 10

    with open(config_path, 'w') as f:
        yaml.dump(base_config, f, default_flow_style=False)

print("‚úì Configs updated for Colab")
```

## üìä Xem k·∫øt qu·∫£

```python
import json
import matplotlib.pyplot as plt

# Load results
results_path = 'colab_outputs/results/metrics.json'
if os.path.exists(results_path):
    with open(results_path, 'r') as f:
        results = json.load(f)

    print("=== PB-GSE Results ===")
    print(f"Coverage: {results['coverage']:.3f}")
    print(f"Balanced Selective Error: {results['balanced_selective_error']:.3f}")
    print(f"Worst-Group Error: {results['worst_group_selective_error']:.3f}")
    print(f"AURC: {results['aurc']:.3f}")

    # Plot results
    metrics = ['coverage', 'balanced_selective_error', 'worst_group_selective_error', 'aurc']
    values = [results[m] for m in metrics]

    plt.figure(figsize=(10, 6))
    plt.bar(metrics, values)
    plt.title('PB-GSE Results')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
```

## üîß Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p:

1. **Out of Memory:**

   ```python
   # Gi·∫£m batch size
   config['data']['batch_size'] = 64
   config['gating']['batch_size'] = 256
   ```

2. **Dataset download ch·∫≠m:**

   ```python
   # CIFAR-10 s·∫Ω t·ª± ƒë·ªông download, ch·ªù kho·∫£ng 5-10 ph√∫t
   ```

3. **Import errors:**
   ```python
   # Ensure Python path
   import sys
   sys.path.append('/content/PB-GSE')
   ```

### Performance Tips:

1. **S·ª≠ d·ª•ng GPU:**

   ```python
   # Ki·ªÉm tra GPU
   import torch
   print(f"CUDA available: {torch.cuda.is_available()}")
   print(f"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
   ```

2. **TƒÉng t·ªëc training:**

   ```python
   # S·ª≠ d·ª•ng mixed precision
   config['use_amp'] = True

   # Gi·∫£m epochs cho demo
   config['demo_mode'] = True
   ```

## üìù L∆∞u k·∫øt qu·∫£

```python
# Download results
from google.colab import files

# Zip results
!zip -r colab_results.zip colab_outputs/

# Download
files.download('colab_results.zip')
```

## üéØ Next Steps

Sau khi ch·∫°y th√†nh c√¥ng tr√™n Colab:

1. **ƒêi·ªÅu ch·ªânh hyperparameters** trong config files
2. **Th·ª≠ c√°c datasets kh√°c** (CIFAR-100-LT)
3. **Ch·∫°y ablation studies**
4. **So s√°nh v·ªõi baselines**

```python
# Ch·∫°y ablation study
!python pb_gse/scripts/run_ablation.py \
    --base_config pb_gse/configs/experiment.yaml \
    --output_dir ./ablation_outputs \
    --only_generate

# Ch·∫°y baseline comparison
!python pb_gse/scripts/evaluate_baselines.py \
    --config pb_gse/configs/experiment.yaml \
    --probs_dir colab_outputs/probs_calibrated \
    --output_dir ./baseline_results
```

## üìö Resources

- **Paper**: [Link to paper when published]
- **GitHub**: https://github.com/your-repo/PB-GSE
- **Documentation**: See README.md
- **Issues**: Report on GitHub Issues

---

**üéâ Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi PB-GSE tr√™n Google Colab!**
